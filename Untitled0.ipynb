{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+lfUOtrM5Gl1y1awu0Aiz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Atanu-2002/Caprae-Capital-/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VvVZcpz_FZ0",
        "outputId": "d2095962-931b-4db6-f676-5a6ddf2b5329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: Levenshtein==0.27.1 in /usr/local/lib/python3.11/dist-packages (from python-Levenshtein) (0.27.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\n",
            "--- Step 1: Loading Libraries ---\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn fuzzywuzzy python-Levenshtein\n",
        "# --- 1. Load the Libraries ---\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "import numpy as np\n",
        "import re # For regular expressions in text cleaning\n",
        "\n",
        "\n",
        "print(\"\\n--- Step 1: Loading Libraries ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Load the Dataset ---\n",
        "print(\"\\n--- Step 2: Loading Dataset ---\")\n",
        "leads_df = pd.read_csv(csv_file_path)\n",
        "print(\"Dataset loaded successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG9NlbG1Ba0V",
        "outputId": "aa194edf-2017-42ba-d4e4-7c1f93ab3b4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 2: Loading Dataset ---\n",
            "Dataset loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Duplicate Lead Detection & Merging ---\n",
        "# This section identifies and marks duplicate entries based on company name and website.\n",
        "# We'll use fuzzy matching for robustness against minor variations.\n",
        "\n",
        "print(\"\\n--- Step 3: Performing Duplicate Lead Detection ---\")\n",
        "\n",
        "def clean_string(text):\n",
        "    \"\"\"Lowercase and remove common company suffixes and punctuation.\"\"\"\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'\\b(inc|ltd|llc|corp|group|solutions|company|co)\\b', '', text)\n",
        "    text = re.sub(r'[\\W_]+', '', text) # Remove non-alphanumeric characters\n",
        "    return text.strip()\n",
        "\n",
        "def find_duplicates(df, key_columns, threshold=85):\n",
        "    \"\"\"\n",
        "    Identifies duplicate entries in a DataFrame based on fuzzy matching of key columns.\n",
        "    Returns a list of tuples, where each tuple contains the indices of duplicate rows.\n",
        "    \"\"\"\n",
        "    df_cleaned = df.copy()\n",
        "    for col in key_columns:\n",
        "        df_cleaned[f'{col}_cleaned'] = df_cleaned[col].apply(clean_string)\n",
        "\n",
        "    duplicates = []\n",
        "    processed_indices = set()\n",
        "\n",
        "    for i in range(len(df_cleaned)):\n",
        "        if i in processed_indices:\n",
        "            continue\n",
        "\n",
        "        current_row = df_cleaned.iloc[i]\n",
        "        potential_duplicates = [i]\n",
        "\n",
        "        for j in range(i + 1, len(df_cleaned)):\n",
        "            if j in processed_indices:\n",
        "                continue\n",
        "\n",
        "            compare_row = df_cleaned.iloc[j]\n",
        "\n",
        "            # Compare company name and website using fuzzy string matching\n",
        "            name_similarity = fuzz.token_sort_ratio(current_row['Company Name_cleaned'], compare_row['Company Name_cleaned'])\n",
        "            website_similarity = fuzz.token_sort_ratio(current_row['Website_cleaned'], compare_row['Website_cleaned'])\n",
        "\n",
        "            # If both are similar enough, consider it a potential duplicate group\n",
        "            if name_similarity >= threshold and website_similarity >= threshold:\n",
        "                potential_duplicates.append(j)\n",
        "\n",
        "        if len(potential_duplicates) > 1:\n",
        "            duplicates.append(potential_duplicates)\n",
        "            for idx in potential_duplicates:\n",
        "                processed_indices.add(idx)\n",
        "        else:\n",
        "            processed_indices.add(i) # Mark as processed even if no duplicates found for this row\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "# Define columns to use for duplicate detection\n",
        "key_cols_for_dupes = ['Company Name', 'Website']\n",
        "duplicate_groups = find_duplicates(leads_df, key_cols_for_dupes, threshold=85)\n",
        "\n",
        "print(f\"\\nFound {len(duplicate_groups)} groups of potential duplicates:\")\n",
        "for group in duplicate_groups:\n",
        "    print(f\"  Duplicate Group (indices): {group}\")\n",
        "    print(leads_df.iloc[group][key_cols_for_dupes]) # Display original names/websites for clarity\n",
        "\n",
        "# Mark duplicates in the DataFrame\n",
        "leads_df['is_duplicate'] = False\n",
        "for group in duplicate_groups:\n",
        "    # Mark all but the first entry in each group as a duplicate to be removed/merged\n",
        "    for idx in group[1:]:\n",
        "        leads_df.loc[idx, 'is_duplicate'] = True\n",
        "\n",
        "# Create a de-duplicated DataFrame\n",
        "deduplicated_leads_df = leads_df[leads_df['is_duplicate'] == False].copy()\n",
        "print(f\"\\nOriginal leads: {len(leads_df)} rows\")\n",
        "print(f\"De-duplicated leads: {len(deduplicated_leads_df)} rows\")\n",
        "print(\"\\nFirst 5 rows of the de-duplicated dataset:\")\n",
        "print(deduplicated_leads_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dys8r25CG6E",
        "outputId": "580c5795-b570-4f29-80ed-40921c66a0ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 3: Performing Duplicate Lead Detection ---\n",
            "\n",
            "Found 2 groups of potential duplicates:\n",
            "  Duplicate Group (indices): [0, 4]\n",
            "           Company Name               Website\n",
            "0   Tech Solutions Inc.     techsolutions.com\n",
            "4  Tech Solutions, Inc.  techsolutionsinc.com\n",
            "  Duplicate Group (indices): [1, 5, 17]\n",
            "                Company Name                     Website\n",
            "1         Global Innovations       globalinnovations.com\n",
            "5   Global Innovations Group  globalinnovationsgroup.com\n",
            "17         Global Innovators       globalinnovations.com\n",
            "\n",
            "Original leads: 19 rows\n",
            "De-duplicated leads: 16 rows\n",
            "\n",
            "First 5 rows of the de-duplicated dataset:\n",
            "              Company Name                    Website        Industry  \\\n",
            "0      Tech Solutions Inc.          techsolutions.com        Software   \n",
            "1       Global Innovations      globalinnovations.com      Consulting   \n",
            "2            Alpha Digital           alphadigital.com       Marketing   \n",
            "3       Beta Analytics Ltd        betaanalytics.co.uk  Data Analytics   \n",
            "6  Alpha Digital Solutions  alphadigitalsolutions.com       Marketing   \n",
            "\n",
            "   Employee Count  Revenue (MM USD)   Contact Name          Job Title  \\\n",
            "0              50               5.0    Alice Smith                CEO   \n",
            "1             150              20.0    Bob Johnson   Head of Strategy   \n",
            "2              80              10.0  Charlie Brown  Marketing Manager   \n",
            "3             200              30.0   Diana Prince     Data Scientist   \n",
            "6              85              10.5     Charlie B.     Marketing Lead   \n",
            "\n",
            "   is_duplicate  \n",
            "0         False  \n",
            "1         False  \n",
            "2         False  \n",
            "3         False  \n",
            "6         False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Lead Scoring/Prioritization ---\n",
        "# This section uses Machine Learning to assign a \"score\" to each lead,\n",
        "# indicating its potential value or likelihood to be a good target for Caprae Capital.\n",
        "# Since we don't have historical conversion data, we'll use simple heuristics to\n",
        "# create a 'target' variable for training a supervised ML model.\n",
        "\n",
        "print(\"\\n--- Step 4: Performing Lead Scoring/Prioritization ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP6IoCsbCUsX",
        "outputId": "93235331-4422-48e7-e1f0-3e180684be16"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 4: Performing Lead Scoring/Prioritization ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.1 Feature Engineering and Heuristic Labeling ---\n",
        "\n",
        "# Heuristic function to define \"good\" leads for training purposes\n",
        "# This simulates what Caprae Capital might consider a high-value lead\n",
        "# based on industry, company size, and contact role.\n",
        "\n",
        "# Keywords for decision-maker roles - keep the same\n",
        "# Define this list in the global scope so it's accessible outside the function\n",
        "decision_maker_keywords = ['ceo', 'founder', 'chief executive', 'vp', 'head of', 'director']\n",
        "\n",
        "\n",
        "def assign_heuristic_label(row):\n",
        "    # Example rules for \"good\" leads for Caprae Capital's M&A as a Service\n",
        "    # (These rules are simplified for demonstration and 5-hour constraint)\n",
        "\n",
        "    # --- Slightly relax the heuristic rules ---\n",
        "    # Industry match is the same\n",
        "    industry_match = 'software' in str(row['Industry']).lower() or \\\n",
        "                     'fintech' in str(row['Industry']).lower() or \\\n",
        "                     'ai/ml' in str(row['Industry']).lower() or \\\n",
        "                     'data analytics' in str(row['Industry']).lower()\n",
        "\n",
        "    # Relax employee count requirement\n",
        "    size_match = row['Employee Count'] >= 50 # Lowered from 70\n",
        "\n",
        "    # Use the globally defined decision_maker_keywords\n",
        "    job_title_match = any(keyword in str(row['Job Title']).lower() for keyword in decision_maker_keywords)\n",
        "\n",
        "    # A lead is \"good\" if Industry OR (Size AND Job Title) match\n",
        "    # This makes it easier for a lead to be classified as 1\n",
        "    if industry_match or (size_match and job_title_match):\n",
        "        return 1 # Good Lead\n",
        "    else:\n",
        "        return 0 # Less relevant Lead\n",
        "\n",
        "# Apply the heuristic to create a 'is_good_lead' target variable\n",
        "deduplicated_leads_df['is_good_lead'] = deduplicated_leads_df.apply(assign_heuristic_label, axis=1)\n",
        "print(\"\\nHeuristic 'is_good_lead' labels assigned:\")\n",
        "print(deduplicated_leads_df['is_good_lead'].value_counts())\n",
        "\n",
        "# --- Add a check for class balance before splitting ---\n",
        "if len(deduplicated_leads_df['is_good_lead'].unique()) < 2:\n",
        "    print(\"\\nWarning: Only one class found in 'is_good_lead'. Cannot train a binary classification model.\")\n",
        "    # Depending on requirements, you might stop here, use a different approach,\n",
        "    # or inform the user that the data doesn't support this step.\n",
        "    # For this fix, we'll continue assuming the relaxed rules might help.\n",
        "    # If this warning still appears after relaxing rules, the dataset is likely too small or skewed.\n",
        "\n",
        "\n",
        "# Prepare features (X) and target (y) for the ML model\n",
        "# Select relevant features for scoring. Convert categorical features to numerical using one-hot encoding.\n",
        "features = ['Industry', 'Employee Count', 'Revenue (MM USD)', 'Job Title']\n",
        "X = deduplicated_leads_df[features].copy()\n",
        "y = deduplicated_leads_df['is_good_lead']\n",
        "\n",
        "# One-hot encode categorical features ('Industry' and 'Job Title' keywords)\n",
        "# For Job Title, we'll create features based on decision-maker keywords\n",
        "# Ensure robustness against missing or non-string values using str()\n",
        "# decision_maker_keywords is now accessible here\n",
        "X['is_decision_maker'] = X['Job Title'].apply(lambda x: any(kw in str(x).lower() for kw in decision_maker_keywords))\n",
        "\n",
        "# One-hot encode 'Industry' - handle potential missing values by filling with a placeholder if necessary\n",
        "# Although get_dummies usually handles NaN by not creating a category,\n",
        "# ensuring it's a string type can prevent issues if NaN becomes a string like 'nan'.\n",
        "X['Industry'] = X['Industry'].astype(str)\n",
        "X = pd.get_dummies(X, columns=['Industry'], prefix='Industry', drop_first=True)\n",
        "\n",
        "# Drop original 'Job Title' as we've created a derived feature\n",
        "X = X.drop('Job Title', axis=1)\n",
        "\n",
        "# Ensure all columns are numeric by explicitly converting boolean columns created by get_dummies\n",
        "# and is_decision_maker to integers (0 or 1)\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'bool':\n",
        "        X[col] = X[col].astype(int)\n",
        "\n",
        "# Ensure all columns are numeric after conversions\n",
        "X = X.select_dtypes(include=np.number)\n",
        "\n",
        "\n",
        "print(\"\\nFeatures prepared for ML model:\")\n",
        "print(X.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUHEE0OzCfCV",
        "outputId": "e0a47897-43d0-4001-a870-0e7df6baf480"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Heuristic 'is_good_lead' labels assigned:\n",
            "is_good_lead\n",
            "1    9\n",
            "0    7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Features prepared for ML model:\n",
            "   Employee Count  Revenue (MM USD)  is_decision_maker  Industry_Consulting  \\\n",
            "0              50               5.0                  1                    0   \n",
            "1             150              20.0                  1                    1   \n",
            "2              80              10.0                  0                    0   \n",
            "3             200              30.0                  0                    0   \n",
            "6              85              10.5                  0                    0   \n",
            "\n",
            "   Industry_Data Analytics  Industry_Education  Industry_FinTech  \\\n",
            "0                        0                   0                 0   \n",
            "1                        0                   0                 0   \n",
            "2                        0                   0                 0   \n",
            "3                        1                   0                 0   \n",
            "6                        0                   0                 0   \n",
            "\n",
            "   Industry_Healthcare  Industry_IT Services  Industry_Manufacturing  \\\n",
            "0                    0                     0                       0   \n",
            "1                    0                     0                       0   \n",
            "2                    0                     0                       0   \n",
            "3                    0                     0                       0   \n",
            "6                    0                     0                       0   \n",
            "\n",
            "   Industry_Marketing  Industry_Retail  Industry_Software  \n",
            "0                   0                0                  1  \n",
            "1                   0                0                  0  \n",
            "2                   1                0                  0  \n",
            "3                   0                0                  0  \n",
            "6                   1                0                  0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.2 Model Training ---\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"\\nTraining data shape: {X_train.shape}\")\n",
        "print(f\"Testing data shape: {X_test.shape}\")\n",
        "\n",
        "# Initialize and train a simple Logistic Regression model\n",
        "# Logistic Regression is good for binary classification and provides probabilities (scores)\n",
        "model = LogisticRegression(random_state=42, solver='liblinear') # liblinear is good for small datasets\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nLogistic Regression model trained.\")\n",
        "\n",
        "# Evaluate the model (optional for this challenge, but good practice)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Model Accuracy on test set: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(\"\\nClassification Report on test set:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0)) # zero_division=0 to handle cases where a class might not be present in predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmMyobgHCman",
        "outputId": "3a4f5a46-8ee3-451f-a200-a7ce01006f16"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training data shape: (12, 13)\n",
            "Testing data shape: (4, 13)\n",
            "\n",
            "Logistic Regression model trained.\n",
            "Model Accuracy on test set: 0.75\n",
            "\n",
            "Classification Report on test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.75         4\n",
            "   macro avg       0.83      0.75      0.73         4\n",
            "weighted avg       0.83      0.75      0.73         4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.3 Assign Lead Scores ---\n",
        "\n",
        "# Predict probabilities for all leads (not just test set, as we want scores for all)\n",
        "# The second column [:, 1] gives the probability of being the positive class (1 = 'good lead')\n",
        "deduplicated_leads_df['Lead_Score'] = model.predict_proba(X[X.columns])[:, 1]\n",
        "\n",
        "# Round the score for readability\n",
        "deduplicated_leads_df['Lead_Score'] = deduplicated_leads_df['Lead_Score'].round(2)\n"
      ],
      "metadata": {
        "id": "JOqo5IdeCt04"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Display Final Results ---\n",
        "# Show the de-duplicated leads, sorted by their new Lead_Score.\n",
        "\n",
        "print(\"\\n--- Step 5: Final Results (De-duplicated and Scored Leads) ---\")\n",
        "final_leads_df = deduplicated_leads_df.sort_values(by='Lead_Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nTop 10 leads by predicted score:\")\n",
        "print(final_leads_df[['Company Name', 'Website', 'Industry', 'Employee Count', 'Job Title', 'is_good_lead', 'Lead_Score']].head(10).to_markdown(index=False))\n",
        "\n",
        "print(\"\\n--- Summary of Improvements ---\")\n",
        "print(\"1. **Duplicate Detection:** Identified and marked (or removed) similar entries, leading to cleaner data.\")\n",
        "print(\"   - Before: {} leads\".format(len(leads_df)))\n",
        "print(\"   - After De-duplication: {} unique leads\".format(len(deduplicated_leads_df)))\n",
        "print(\"2. **Lead Scoring:** Applied a Machine Learning model to assign a 'Lead_Score' based on defined criteria, allowing for prioritization.\")\n",
        "print(\"   - Leads can now be sorted from highest potential to lowest, guiding sales efforts.\")\n",
        "print(\"\\nThis prototype demonstrates how ML can transform raw scraped data into actionable insights for Caprae Capital's lead generation process, aligning with their focus on driving real-world impact.\")\n"
      ],
      "metadata": {
        "id": "rvcuawHdEMJB",
        "outputId": "2dd78e51-b5fa-4d5f-f043-2a8bb0ada660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 5: Final Results (De-duplicated and Scored Leads) ---\n",
            "\n",
            "Top 10 leads by predicted score:\n",
            "| Company Name        | Website               | Industry       |   Employee Count | Job Title              |   is_good_lead |   Lead_Score |\n",
            "|:--------------------|:----------------------|:---------------|-----------------:|:-----------------------|---------------:|-------------:|\n",
            "| Zeta Corp           | zetacorp.com          | Manufacturing  |             1000 | Operations Director    |              1 |         0.97 |\n",
            "| Zeta Corporation    | zetacorp.net          | Manufacturing  |             1050 | Director of Operations |              1 |         0.97 |\n",
            "| Global Innovations  | globalinnovations.com | Consulting     |              150 | Head of Strategy       |              1 |         0.74 |\n",
            "| Beta Analytics Ltd  | betaanalytics.co.uk   | Data Analytics |              200 | Data Scientist         |              1 |         0.71 |\n",
            "| Beta Analytics LLC  | beta-analytics.com    | Data Analytics |              210 | Senior Data Analyst    |              1 |         0.71 |\n",
            "| Tech Solutions Inc. | techsolutions.com     | Software       |               50 | CEO                    |              1 |         0.69 |\n",
            "| Gamma Tech          | gammatech.io          | FinTech        |               70 | FinTech Analyst        |              1 |         0.58 |\n",
            "| Gamma Technology    | gammatechnology.io    | FinTech        |               75 | FinTech Spec.          |              1 |         0.58 |\n",
            "| Omega Systems Inc.  | omegasystems.com      | IT Services    |              310 | IT Lead                |              0 |         0.53 |\n",
            "| Omega Systems       | omegasys.net          | IT Services    |              300 | IT Manager             |              0 |         0.52 |\n",
            "\n",
            "--- Summary of Improvements ---\n",
            "1. **Duplicate Detection:** Identified and marked (or removed) similar entries, leading to cleaner data.\n",
            "   - Before: 19 leads\n",
            "   - After De-duplication: 16 unique leads\n",
            "2. **Lead Scoring:** Applied a Machine Learning model to assign a 'Lead_Score' based on defined criteria, allowing for prioritization.\n",
            "   - Leads can now be sorted from highest potential to lowest, guiding sales efforts.\n",
            "\n",
            "This prototype demonstrates how ML can transform raw scraped data into actionable insights for Caprae Capital's lead generation process, aligning with their focus on driving real-world impact.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6VCayKk8EUG8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}